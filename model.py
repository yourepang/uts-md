# -*- coding: utf-8 -*-
"""UTS MD NO 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/150OrNtFK7ZpaatE0FeQ-k7wxPiBr_bkW
"""

import pandas as pd
import pickle
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, RobustScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier

class LoanPredictionModel:
    def __init__(self, filepath):
        self.df = pd.read_csv(filepath)
        self.x_train = None
        self.x_test = None
        self.y_train = None
        self.y_test = None
        self.model = None
        self.encoder = None
        self.ord_encoder = None
        self.scaler = None

    def clean_data(self):
        self.df['person_income'] = self.df['person_income'].fillna(67055.0)
        self.df['person_gender'] = self.df['person_gender'].replace({
            'Male': 'male',
            'fe male': 'female'
        })
        df_encode = {
            "person_gender": {"male": 1, "female": 0},
            "previous_loan_defaults_on_file": {"Yes": 1, "No": 0}
        }
        self.df.replace(df_encode, inplace=True)

        self.encoder = OneHotEncoder()
        encoded = self.encoder.fit_transform(self.df[['loan_intent', 'person_home_ownership']])
        df_encoded = pd.DataFrame(encoded.toarray(), columns=self.encoder.get_feature_names_out())

        self.df.reset_index(drop=True, inplace=True)
        self.df = pd.concat([self.df, df_encoded], axis=1)

        self.ord_encoder = OrdinalEncoder(categories=[['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate']])
        self.df[['person_education']] = self.ord_encoder.fit_transform(self.df[['person_education']])

        self.df.drop(columns=['person_home_ownership', 'loan_intent'], inplace=True)

    def scale_features(self):
        cols_to_scale = [
            'person_age',
            'person_income',
            'person_emp_exp',
            'loan_amnt',
            'loan_int_rate',
            'loan_percent_income',
            'cb_person_cred_hist_length',
            'credit_score'
        ]
        self.scaler = RobustScaler()
        self.df[cols_to_scale] = self.scaler.fit_transform(self.df[cols_to_scale])

    def split_data(self):
        input_data = self.df.drop(columns=['loan_status'])
        output_data = self.df['loan_status']
        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(
            input_data, output_data, test_size=0.2, random_state=0
        )

    def train_model(self):
        self.model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
        self.model.fit(self.x_train, self.y_train)

    def evaluate_model(self):
        y_pred = self.model.predict(self.x_test)
        print("Accuracy:", accuracy_score(self.y_test, y_pred))
        print("Classification Report:\n", classification_report(self.y_test, y_pred))

    def tune_model(self):
        param_dist = {
            'n_estimators': [100, 200, 300],
            'max_depth': [3, 5, 10],
            'learning_rate': [0.01, 0.1, 0.3],
            'subsample': [0.6, 0.8, 1.0],
            'colsample_bytree': [0.6, 0.8, 1.0]
        }

        search = RandomizedSearchCV(
            estimator=XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),
            param_distributions=param_dist,
            n_iter=10,
            scoring='f1',
            cv=5,
            random_state=42,
            n_jobs=-1,
            verbose=2
        )

        search.fit(self.x_train, self.y_train)
        print("Best parameters:", search.best_params_)
        print("Best score:", search.best_score_)

        self.model = search.best_estimator_

    def run_all(self, tune=False):
        print("Cleaning data...")
        self.clean_data()
        print("Scaling features...")
        self.scale_features()
        print("Splitting dataset...")
        self.split_data()
        if tune:
            print("Tuning model...")
            self.tune_model()
        else:
            print("Training model...")
            self.train_model()
        print("Evaluating model...")
        self.evaluate_model()

        # Simpan model dan transformer
        with open('loan_model.pkl', 'wb') as f:
            pickle.dump(self.model, f)
        with open('encoder.pkl', 'wb') as f:
            pickle.dump(self.encoder, f)
        with open('ord_encoder.pkl', 'wb') as f:
            pickle.dump(self.ord_encoder, f)
        with open('scaler.pkl', 'wb') as f:
            pickle.dump(self.scaler, f)

    def predict_from_file(self, input_csv, output_csv=None):
        df = pd.read_csv(input_csv)

        with open('loan_model.pkl', 'rb') as f:
            model = pickle.load(f)
        with open('encoder.pkl', 'rb') as f:
            encoder = pickle.load(f)
        with open('ord_encoder.pkl', 'rb') as f:
            ord_encoder = pickle.load(f)
        with open('scaler.pkl', 'rb') as f:
            scaler = pickle.load(f)

        df['person_gender'] = df['person_gender'].replace({'Male': 'male', 'fe male': 'female'})
        df.replace({
            "person_gender": {"male": 1, "female": 0},
            "previous_loan_defaults_on_file": {"Yes": 1, "No": 0}
        }, inplace=True)

        encoded = encoder.transform(df[['loan_intent', 'person_home_ownership']])
        df_encoded = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out())
        df.reset_index(drop=True, inplace=True)
        df = pd.concat([df, df_encoded], axis=1)

        df[['person_education']] = ord_encoder.transform(df[['person_education']])
        df.drop(columns=['loan_intent', 'person_home_ownership'], inplace=True)

        cols_to_scale = [
            'person_age',
            'person_income',
            'person_emp_exp',
            'loan_amnt',
            'loan_int_rate',
            'loan_percent_income',
            'cb_person_cred_hist_length',
            'credit_score'
        ]
        df[cols_to_scale] = scaler.transform(df[cols_to_scale])

        pred = model.predict(df)
        df['loan_prediction'] = pred

        if output_csv:
            df.to_csv(output_csv, index=False)
            print(f"Hasil prediksi disimpan ke {output_csv}")
        else:
            print(df[['loan_prediction']].head())

if __name__ == '__main__':
    model = LoanPredictionModel('Dataset_A_loan.csv')
    model.run_all(tune=False)

    df_all = pd.read_csv('Dataset_A_loan.csv')
    df_uji = df_all.drop(columns=['loan_status'])  # hapus kolom label
    df_uji_sample = df_uji.sample(n=10, random_state=42)  # ambil 10 data acak
    df_uji_sample.to_csv('data_uji.csv', index=False)

    model.predict_from_file('data_uji.csv', 'hasil_prediksi.csv')